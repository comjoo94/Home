{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJkHzjAw9i4Q"
      },
      "source": [
        "**6장 – RNN과 CNN을 사용해 시퀀스 처리하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": []
      },
      "source": [
        "# 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPbJEmZpKzu"
      },
      "source": [
        "이 프로젝트에는 Python 3.7 이상이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFSU3FCOpKzu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtVEqxfpKzw"
      },
      "source": [
        "그리고 TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDaDoLQTpKzx"
      },
      "source": [
        "이전 챕터에서 했던 것처럼 기본 글꼴 크기를 정의하여 그림을 더 예쁘게 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d4TH3NbpKzx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)\n",
        "\n",
        "import sys\n",
        "# 코랩의 경우 나눔 폰트를 설치합니다.\n",
        "if 'google.colab' in sys.modules:\n",
        "    !sudo apt-get -qq -y install fonts-nanum\n",
        "    import matplotlib.font_manager as fm\n",
        "    font_files = fm.findSystemFonts(fontpaths=['/usr/share/fonts/truetype/nanum'])\n",
        "    for fpath in font_files:\n",
        "        fm.fontManager.addfont(fpath)\n",
        "\n",
        "# 나눔 폰트를 사용합니다.\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.rc('font', family='NanumBarunGothic')\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcoUIRsvpKzy"
      },
      "source": [
        "그리고 `images/rnn` 폴더를 만들고(아직 존재하지 않는 경우), 이 노트북을 통해 책에 사용할 그림을 고해상도로 저장하는 데 사용되는 `save_fig()` 함수를 정의해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQFH5Y9PpKzy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"rnn\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTsawKlapKzy"
      },
      "source": [
        "이 챕터는 GPU가 없으면 매우 느려질 수 있으므로 GPU가 있는지 확인하거나 그렇지 않으면 경고를 표시합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekxzo6pOpKzy"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU가 감지되지 않았습니다. 신경망은 GPU가 없으면 매우 느릴 수 있습니다.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"런타임 > 런타임 유형 변경으로 이동하여 GPU를 선택하세요.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7p0gDSP9i4r"
      },
      "source": [
        "# 기본 RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqSZA_lD9i4r"
      },
      "source": [
        "`ageron/data` 저장소트에서 승객 데이터를 다운로드해 보겠습니다. 원래는 시카고 교통국에서 제공한 것으로, [시카고 데이터 포털](https://homl.info/ridership)에서 다운로드할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPAgnesQ9i40"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.get_file(\n",
        "    \"ridership.tgz\",\n",
        "    \"https://github.com/ageron/data/raw/main/ridership.tgz\",\n",
        "    cache_dir=\".\",\n",
        "    extract=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOYIXxRZ9i47"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
        "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
        "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # 더 짧은 이름\n",
        "df = df.sort_values(\"date\").set_index(\"date\")\n",
        "df = df.drop(\"total\", axis=1)  # total은 단순히 bus + rail 이므로 삭제합니다.\n",
        "df = df.drop_duplicates()  # 중복된 월 제거 (2011-10와 2014-07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99aKJDKo9i47"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA_XW6oS9i48"
      },
      "source": [
        "2019년의 첫 몇 달을 살펴봅시다(판다스에서는 범위의 경계를 포함합니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA0Lrd519i48"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"2019-03\":\"2019-05\"].plot(grid=True, marker=\".\", figsize=(8, 3.5))\n",
        "plt.legend([\"버스\", \"열차\"]);\n",
        "plt.xlabel(\"날짜\")\n",
        "save_fig(\"daily_ridership_plot\")  # 추가 코드 - 책의 그림을 저장합니다.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6TOSbhl9i48"
      },
      "outputs": [],
      "source": [
        "diff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\n",
        "df.plot(ax=axs[0], legend=False, marker=\".\")  # 원본 시계열\n",
        "df.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # 지연\n",
        "diff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7일 차분 시계열\n",
        "axs[1].legend([\"버스\", \"열차\"])\n",
        "axs[1].set_xlabel(\"날짜\")\n",
        "axs[0].set_ylim([170_000, 900_000])  # 추가 코드 - 그래프를 아름답게 꾸미기\n",
        "save_fig(\"differencing_plot\")  # 추가 코드 - 책의 그림을 저장합니다.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emEdmLkS9i49",
        "tags": []
      },
      "outputs": [],
      "source": [
        "list(df.loc[\"2019-05-25\":\"2019-05-27\"][\"day_type\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeIK90K_9i49"
      },
      "source": [
        "평균 절대 오차(MAE)는 평균 절대 편차(MAD)라고도 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5INjvZkW9i49"
      },
      "outputs": [],
      "source": [
        "diff_7.abs().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwQuXFfi9i4-"
      },
      "source": [
        "평균 절대 비율 오류(MAPE):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8FJEWJK9i4-"
      },
      "outputs": [],
      "source": [
        "targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n",
        "(diff_7 / targets).abs().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuXlris19i4-"
      },
      "source": [
        "이제 연도별 계절성과 장기 트렌드를 살펴보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJWxsYJ99i4-"
      },
      "outputs": [],
      "source": [
        "period = slice(\"2001\", \"2019\")\n",
        "df_monthly = df.resample('M').mean(numeric_only=True)  # 월별 평균을 계산합니다.\n",
        "rolling_average_12_months = df_monthly[period].rolling(window=12).mean()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "df_monthly[period].plot(ax=ax, marker=\".\")\n",
        "rolling_average_12_months.plot(ax=ax, grid=True, legend=False)\n",
        "ax.legend([\"버스\", \"열차\"]);\n",
        "ax.set_xlabel('날짜')\n",
        "save_fig(\"long_term_ridership_plot\")  # 추가 코드 - 책의 그림을 저장합니다.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyDaWVz49i4_"
      },
      "outputs": [],
      "source": [
        "df_monthly.diff(12)[period].plot(grid=True, marker=\".\", figsize=(8, 3))\n",
        "plt.legend([\"버스\", \"열차\"])\n",
        "plt.xlabel(\"날짜\")\n",
        "save_fig(\"yearly_diff_plot\")  # 추가 코드 - 책의 그림을 저장합니다.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGEf9Ih9i4_"
      },
      "source": [
        "Colab에서 실행하는 경우 `statsmodels` 라이브러리를 설치합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34MnZNRj9i4_"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    %pip install -q -U statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPmzraWY9i4_"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "origin, today = \"2019-01-01\", \"2019-05-31\"\n",
        "rail_series = df.loc[origin:today][\"rail\"].asfreq(\"D\")\n",
        "model = ARIMA(rail_series,\n",
        "              order=(1, 0, 0),\n",
        "              seasonal_order=(0, 1, 1, 7))\n",
        "model = model.fit()\n",
        "y_pred = model.forecast()  # 427,758.6 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ZOpuil9i5A"
      },
      "outputs": [],
      "source": [
        "y_pred[0]  # ARIMA 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gpn622cY9i5B"
      },
      "outputs": [],
      "source": [
        "df[\"rail\"].loc[\"2019-06-01\"]  # 타깃 값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z77JLBDk9i5B"
      },
      "outputs": [],
      "source": [
        "df[\"rail\"].loc[\"2019-05-25\"]  # 순진한 예측(1주일 전의 값)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMSLkVg39i5C"
      },
      "outputs": [],
      "source": [
        "origin, start_date, end_date = \"2019-01-01\", \"2019-03-01\", \"2019-05-31\"\n",
        "time_period = pd.date_range(start_date, end_date)\n",
        "rail_series = df.loc[origin:end_date][\"rail\"].asfreq(\"D\")\n",
        "y_preds = []\n",
        "for today in time_period.shift(-1):\n",
        "    model = ARIMA(rail_series[origin:today],  # \"오늘\"까지의 데이터로 훈련\n",
        "                  order=(1, 0, 0),\n",
        "                  seasonal_order=(0, 1, 1, 7))\n",
        "    model = model.fit()  # 매일 모델을 재훈련한다는 점에 유의하세요!\n",
        "    y_pred = model.forecast()[0]\n",
        "    y_preds.append(y_pred)\n",
        "\n",
        "y_preds = pd.Series(y_preds, index=time_period)\n",
        "mae = (y_preds - rail_series[time_period]).abs().mean()  # 32,040.7 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4nDhrBH9i5C"
      },
      "outputs": [],
      "source": [
        "mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyPUYHxs9i5C"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - SARIMA 예측을 표시합니다.\n",
        "fig, ax = plt.subplots(figsize=(8, 3))\n",
        "rail_series.loc[time_period].plot(label=\"실제\", ax=ax, marker=\".\", grid=True)\n",
        "ax.plot(y_preds, color=\"r\", marker=\".\", label=\"SARIMA 예측\")\n",
        "ax.set_xlabel(\"날짜\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNXbBuR29i5D"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 자기 상관관계 함수(ACF) 및\n",
        "# 부분 자기 상관관계 함수(PACF)를 그리는 방법을 보여줍니다.\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "plot_acf(df[period][\"rail\"], ax=axs[0], lags=35, title=\"자기상관\")\n",
        "axs[0].grid()\n",
        "plot_pacf(df[period][\"rail\"], ax=axs[1], lags=35, method=\"ywm\",\n",
        "          title=\"부분 자기상관\")\n",
        "axs[1].grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEqIt0EM9i5D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "my_series = [0, 1, 2, 3, 4, 5]\n",
        "my_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    my_series,\n",
        "    targets=my_series[3:],  # 타깃은 미래 3 스텝 앞의 값입니다.\n",
        "    sequence_length=3,\n",
        "    batch_size=2\n",
        ")\n",
        "list(my_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55c8P2pH9i5D"
      },
      "outputs": [],
      "source": [
        "for window_dataset in tf.data.Dataset.range(6).window(4, shift=1):\n",
        "    for element in window_dataset:\n",
        "        print(f\"{element}\", end=\" \")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9AOQWbD9i5E"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.range(6).window(4, shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window_dataset: window_dataset.batch(4))\n",
        "for window_tensor in dataset:\n",
        "    print(f\"{window_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFwpIDhR9i5E"
      },
      "outputs": [],
      "source": [
        "def to_windows(dataset, length):\n",
        "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
        "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3CercaN9i5E"
      },
      "outputs": [],
      "source": [
        "dataset = to_windows(tf.data.Dataset.range(6), 4)\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "list(dataset.batch(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wae4FNZv9i5F"
      },
      "source": [
        "데이터를 계속 살펴보기 전에 훈련, 검증 및 테스트를 위해 시계열을 세 가지 기간으로 나누어 보겠습니다. 지금은 테스트 데이터를 살펴보지 않겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17qcHzqF9i5F"
      },
      "outputs": [],
      "source": [
        "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6\n",
        "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
        "rail_test = df[\"rail\"][\"2019-06\":] / 1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkulHlvq9i5F"
      },
      "outputs": [],
      "source": [
        "seq_length = 56\n",
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_train.to_numpy(),\n",
        "    targets=rail_train[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    rail_valid.to_numpy(),\n",
        "    targets=rail_valid[seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM7YHzxv9i5I"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
        "])\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
        "history = model.fit(train_ds, validation_data=valid_ds, epochs=500,\n",
        "                    callbacks=[early_stopping_cb])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2swfjfh9i5I"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 모델을 평가합니다.\n",
        "valid_loss, valid_mae = model.evaluate(valid_ds)\n",
        "valid_mae * 1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwIX-i0R9i5I"
      },
      "source": [
        "## 간단한 RNN 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxMxuoqx9i5M"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9kwvI6o9i5M"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 여러 번 재사용할 유틸리티 함수를 정의합니다.\n",
        "\n",
        "def fit_and_evaluate(model, train_set, valid_set, learning_rate, epochs=500):\n",
        "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
        "    history = model.fit(train_set, validation_data=valid_set, epochs=epochs,\n",
        "                        callbacks=[early_stopping_cb])\n",
        "    valid_loss, valid_mae = model.evaluate(valid_set)\n",
        "    return valid_mae * 1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfK4onlh9i5N"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(model, train_ds, valid_ds, learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7Byyqcu9i5N"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "univar_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
        "    tf.keras.layers.Dense(1)  # 기본적으로 활성화 함수 없음\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ9HP7pH9i5N"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이전과 같이 모델을 컴파일, 훈련 및 평가합니다.\n",
        "fit_and_evaluate(univar_model, train_ds, valid_ds, learning_rate=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkKTNSf79i5O"
      },
      "source": [
        "## 심층 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MnrN76G9i5O"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "deep_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
        "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
        "    tf.keras.layers.SimpleRNN(32),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaQtAbgv9i5O"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이전과 같이 모델을 컴파일, 훈련 및 평가합니다.\n",
        "fit_and_evaluate(deep_model, train_ds, valid_ds, learning_rate=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2na3s3M9i5O"
      },
      "source": [
        "## 다변량 시계열"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O44xIqKA9i5P"
      },
      "outputs": [],
      "source": [
        "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # 버스 및 열차 시계열을 모두 입력으로 사용\n",
        "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # 내일의 유형을 알고 있습니다.\n",
        "df_mulvar = pd.get_dummies(df_mulvar)  # 요일 유형을 원-핫 인코딩합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb7Pm-Zw9i5P"
      },
      "outputs": [],
      "source": [
        "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
        "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
        "mulvar_test = df_mulvar[\"2019-06\":]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3XiUVI39i5P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "\n",
        "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(np.float32),  # 5개의 열을 모두 입력으로 사용\n",
        "    targets=mulvar_train[\"rail\"][seq_length:],  # 열차 시계열만 예측\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(np.float32),\n",
        "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaY12mmL9i5P"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "mulvar_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4F_cHju9i5P"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이전과 같이 모델을 컴파일, 훈련 및 평가합니다.\n",
        "fit_and_evaluate(mulvar_model, train_mulvar_ds, valid_mulvar_ds,\n",
        "                 learning_rate=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-2hs7y99i5Q"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 버스와 열차를 모두 예측하는 멀티태스크 RNN 구축 및 훈련\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "seq_length = 56\n",
        "train_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(np.float32),\n",
        "    targets=mulvar_train[[\"bus\", \"rail\"]][seq_length:],  # 타깃 2개\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "valid_multask_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(np.float32),\n",
        "    targets=mulvar_valid[[\"bus\", \"rail\"]][seq_length:],\n",
        "    sequence_length=seq_length,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "multask_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "fit_and_evaluate(multask_model, train_multask_ds, valid_multask_ds,\n",
        "                 learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHno6SRT9i5Q"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 버스에 대한 순진한 예측을 평가합니다.\n",
        "bus_naive = mulvar_valid[\"bus\"].shift(7)[seq_length:]\n",
        "bus_target = mulvar_valid[\"bus\"][seq_length:]\n",
        "(bus_target - bus_naive).abs().mean() * 1e6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHLgRQfE9i5Q"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 버스와 열차 모두에 대한 멀티태스크 RNN의 예측을 평가합니다.\n",
        "Y_preds_valid = multask_model.predict(valid_multask_ds)\n",
        "for idx, name in enumerate([\"bus\", \"rail\"]):\n",
        "    mae = 1e6 * tf.keras.metrics.mean_absolute_error(\n",
        "        mulvar_valid[name][seq_length:], Y_preds_valid[:, idx])\n",
        "    print(name, int(mae))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqknH78k9i5Q"
      },
      "source": [
        "## 여러 스텝 앞을 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjU7ODjq9i5Q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
        "for step_ahead in range(14):\n",
        "    y_pred_one = univar_model.predict(X)\n",
        "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC02tAVx9i5R"
      },
      "outputs": [],
      "source": [
        "# 추가 코드\n",
        "\n",
        "# 예측은 2019년 57일째인 2019-02-26에 시작하여 2019-03-11에 종료됩니다. 총 14일입니다.\n",
        "Y_pred = pd.Series(X[0, -14:, 0],\n",
        "                   index=pd.date_range(\"2019-02-26\", \"2019-03-11\"))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
        "(rail_valid * 1e6)[\"2019-02-01\":\"2019-03-11\"].plot(\n",
        "    label=\"진짜\", marker=\".\", ax=ax)\n",
        "(Y_pred * 1e6).plot(\n",
        "    label=\"예측\", grid=True, marker=\"x\", color=\"r\", ax=ax)\n",
        "ax.vlines(\"2019-02-25\", 0, 1e6, color=\"k\", linestyle=\"--\", label=\"오늘\")\n",
        "ax.set_ylim([200_000, 800_000])\n",
        "ax.set_xlabel(\"날짜\")\n",
        "plt.legend(loc=\"center left\")\n",
        "save_fig(\"forecast_ahead_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpHWSzic9i5R"
      },
      "source": [
        "이제 14개의 다음 값을 한 번에 모두 예측하는 RNN을 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFyNwxz89i5R"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "\n",
        "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
        "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
        "\n",
        "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_train.to_numpy(np.float32),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 14,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ").map(split_inputs_and_targets)\n",
        "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    mulvar_valid.to_numpy(np.float32),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 14,\n",
        "    batch_size=32\n",
        ").map(split_inputs_and_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3-ifzkF9i5R"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "ahead_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgSudVKo9i5S"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 이전과 같이 모델을 컴파일, 훈련 및 평가합니다.\n",
        "fit_and_evaluate(ahead_model, ahead_train_ds, ahead_valid_ds,\n",
        "                 learning_rate=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8rDQTF9i5S"
      },
      "outputs": [],
      "source": [
        "X = mulvar_valid.to_numpy(np.float32)[np.newaxis, :seq_length]  # 크기 [1, 56, 5]\n",
        "Y_pred = ahead_model.predict(X)  # 크기 [1, 14]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JQ5QiEW9i5S"
      },
      "source": [
        "이제 각 타임 스텝에서 다음 14스텝을 예측하는 RNN을 만들어 보겠습니다. 즉, 타임 스텝 0\\~55를 기준으로 타임 스텝 56\\~69를 예측하는 대신 타임 스텝 0에서 타임 스텝 1\\~14를 예측하고, 타임 스텝 1에서 타임 스텝 2\\~15를 예측하는 식으로 예측하고, 마지막 타임 스텝에서 타임 스텝 56\\~69를 예측합니다. 이 모델은 코잘(causal) 모델이므로 어떤 타임 스텝에서든 예측을 할 때는 과거의 타임 스텝만 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yynMbfu9i5S"
      },
      "source": [
        "데이터셋을 준비하기 위해 `to_windows()`를 두 번 사용하여 다음과 같이 연속된 윈도의 시퀀스를 가져올 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8QKPGAq9i5S"
      },
      "outputs": [],
      "source": [
        "my_series = tf.data.Dataset.range(7)\n",
        "dataset = to_windows(to_windows(my_series, 3), 4)\n",
        "list(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9R3MEt9i5T"
      },
      "source": [
        "그런 다음 원소를 원하는 입력과 타깃으로 분할할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e58kNsTU9i5T"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
        "list(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O64sr4xl9i5T"
      },
      "source": [
        "이 아이디어를 유틸리티 함수로 만들어 봅시다. 이 함수는 셔플(선택 사항)과 배치 처리도 담당합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2i9e7169i5T"
      },
      "outputs": [],
      "source": [
        "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
        "                       batch_size=32, shuffle=False, seed=None):\n",
        "    ds = to_windows(tf.data.Dataset.from_tensor_slices(\n",
        "        series.to_numpy(np.float32)), ahead + 1)\n",
        "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:, 1:, 1]))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
        "    return ds.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7UZYySX9i5T"
      },
      "outputs": [],
      "source": [
        "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
        "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDgasbLn9i5U"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "seq2seq_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "    # tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(14))나\n",
        "    # tf.keras.layers.Conv1D(14, kernel_size=1) 와 동일합니다\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84URicBY9i5U"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(seq2seq_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExtQNKrU9i5U"
      },
      "outputs": [],
      "source": [
        "X = mulvar_valid.to_numpy(np.float32)[np.newaxis, :seq_length]\n",
        "y_pred_14 = seq2seq_model.predict(X)[0, -1]  # 마지막 타임 스텝의 출력만"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhIojJ2I9i5U"
      },
      "outputs": [],
      "source": [
        "Y_pred_valid = seq2seq_model.predict(seq2seq_valid)\n",
        "for ahead in range(14):\n",
        "    preds = pd.Series(Y_pred_valid[:-1, -1, ahead],\n",
        "                      index=mulvar_valid.index[56 + ahead : -14 + ahead])\n",
        "    mae = (preds - mulvar_valid[\"rail\"]).abs().mean() * 1e6\n",
        "    print(f\"MAE for +{ahead + 1}: {mae:,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "201p6fy59i5U"
      },
      "source": [
        "# 층 정규화를 사용한 심층 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epx-G5Fs9i5V"
      },
      "outputs": [],
      "source": [
        "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.state_size = units\n",
        "        self.output_size = units\n",
        "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units,\n",
        "                                                             activation=None)\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
        "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
        "        return norm_outputs, [norm_outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56bYpEfz9i5V"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "custom_ln_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True,\n",
        "                        input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbJu88qL9i5V"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L98VdSmn9i5V"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(custom_ln_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9Bfym99i5W"
      },
      "source": [
        "# 추가 자료 - 사용자 정의 RNN 클래스 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtzcsbrF9i5W"
      },
      "source": [
        "RNN 클래스는 마법이 아닙니다. 사실, 자신만의 RNN 클래스를 구현하는 것은 그리 어렵지 않습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgZ20BwA9i5W"
      },
      "outputs": [],
      "source": [
        "class MyRNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.cell = cell\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "    def get_initial_state(self, inputs):\n",
        "        try:\n",
        "            return self.cell.get_initial_state(inputs)\n",
        "        except AttributeError:\n",
        "            # self.cell에 get_initial_state() 메서드가 없는 경우 0으로 돌아갑니다.\n",
        "            batch_size = tf.shape(inputs)[0]\n",
        "            return [tf.zeros([batch_size, self.cell.state_size],\n",
        "                             dtype=inputs.dtype)]\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        states = self.get_initial_state(inputs)\n",
        "        shape = tf.shape(inputs)\n",
        "        batch_size = shape[0]\n",
        "        n_steps = shape[1]\n",
        "        sequences = tf.TensorArray(\n",
        "            inputs.dtype, size=(n_steps if self.return_sequences else 0))\n",
        "        outputs = tf.zeros(shape=[batch_size, self.cell.output_size],\n",
        "                           dtype=inputs.dtype)\n",
        "        for step in tf.range(n_steps):\n",
        "            outputs, states = self.cell(inputs[:, step], states)\n",
        "            if self.return_sequences:\n",
        "                sequences = sequences.write(step, outputs)\n",
        "\n",
        "        if self.return_sequences:\n",
        "            # 출력을 [time steps, batch size, dims] 크기의 배열로 쌓습니다.\n",
        "            # 그다음 전치하여 [batch size, time steps, dims] 크기로 만듭니다.\n",
        "            return tf.transpose(sequences.stack(), [1, 0, 2])\n",
        "        else:\n",
        "            return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n93GnG69i5Y"
      },
      "source": [
        "`@tf.function`은 `for` 루프 전에 `output` 변수를 생성해야 하므로, 해당 값을 전혀 사용하지 않더라도 그 값을 0 텐서로 초기화합니다. 함수가 그래프로 변환되면 이 사용되지 않은 값은 그래프에서 잘려나가므로 성능에 영향을 미치지 않습니다. 마찬가지로 `@tf.function`은 `self.return_sequences`가 `False`인 경우에도 `sequences` 변수가 사용되는 `if` 문 앞에 생성되어야 하므로, 이 경우에는 0 크기의 `TensorArray`를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqZPWbNK9i5Z"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "custom_model = tf.keras.Sequential([\n",
        "    MyRNN(LNSimpleRNNCell(32), return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6-M7w_Q9i5Z"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "errz27w39i5Z"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(custom_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWE3qH69i5Z"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOZJDQpN9i5c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvqGJ-719i5c"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcsRQM8s9i5c"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(lstm_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__8j-sp-9i5c"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnKZ-acx9i5d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "gru_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(32, return_sequences=True, input_shape=[None, 5]),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zysqjKfW9i5d"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q3I8ib89i5d"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(gru_model, seq2seq_train, seq2seq_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usV26kdX9i5d"
      },
      "source": [
        "## 1D 합성곱 층으로 시퀀스 다루기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR1pA0BP9i5d"
      },
      "source": [
        "```\n",
        "  |-----0-----|      |-----3----|      |--... |-------52------|\n",
        "         |-----1----|      |-----4----|   ... |       |-------53------|\n",
        "               |-----2----|     |------5--...-51------|       |-------54------|\n",
        "X:  0  1  2  3  4  5  6  7  8  9 10 11 12 ...  104 105 106 107 108 109 110 111\n",
        "Y:      from 4     6     8    10    12    ...      106     108     110     112\n",
        "         to 17    19    21    23    25    ...      119     121     123     125\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNVcZ37z9i5e"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "conv_rnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2,\n",
        "                           activation=\"relu\", input_shape=[None, 5]),\n",
        "    tf.keras.layers.GRU(32, return_sequences=True),\n",
        "    tf.keras.layers.Dense(14)\n",
        "])\n",
        "\n",
        "longer_train = to_seq2seq_dataset(mulvar_train, seq_length=112,\n",
        "                                       shuffle=True, seed=42)\n",
        "longer_valid = to_seq2seq_dataset(mulvar_valid, seq_length=112)\n",
        "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:, 3::2]))\n",
        "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:, 3::2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMrdj-LV9i5e"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9IMTzrn9i5e"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(conv_rnn_model, downsampled_train, downsampled_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaEYQYnK9i5e"
      },
      "source": [
        "## WaveNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njxwZk4G9i5f"
      },
      "source": [
        "```\n",
        " ⋮\n",
        "C2  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\...\n",
        "   \\  /  \\  /  \\  /  \\  /  \\  /  \\  /  \\     \n",
        "     /    \\      /    \\      /    \\          \n",
        "C1  /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\ /\\  /\\ /...\\\n",
        "X: 0  1  2  3  4  5  6  7  8  9  10 11 12 ... 111\n",
        "Y: 1  2  3  4  5  6  7  8  9  10 11 12 13 ... 112\n",
        " /14 15 16 17 18 19 20 21 22  23 24 25 26 ... 125\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8XluLz-9i5f"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)  # 추가 코드 - 재현성 보장\n",
        "wavenet_model = tf.keras.Sequential()\n",
        "wavenet_model.add(tf.keras.layers.InputLayer(input_shape=[None, 5]))\n",
        "for rate in (1, 2, 4, 8) * 2:\n",
        "    wavenet_model.add(tf.keras.layers.Conv1D(\n",
        "        filters=32, kernel_size=2, padding=\"causal\", activation=\"relu\",\n",
        "        dilation_rate=rate))\n",
        "wavenet_model.add(tf.keras.layers.Conv1D(filters=14, kernel_size=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVXr9vnR9i5f"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwYlVMHE9i5f"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(wavenet_model, longer_train, longer_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZEjGrRa9i5f"
      },
      "source": [
        "# 추가 자료 – Wavenet 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conbBcCe9i5f"
      },
      "source": [
        "다음은 논문에 정의된 WaveNet 구현입니다. ReLU와 파라미터를 가진 스킵 연결 대신 게이트 활성화 유닛(Gated Activation Unit)을 사용하며, 시퀀스가 점점 짧아지는 것을 방지하기 위해 왼쪽에 0으로 패딩합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyuDXZNi9i5g"
      },
      "outputs": [],
      "source": [
        "class GatedActivationUnit(tf.keras.layers.Layer):\n",
        "    def __init__(self, activation=\"tanh\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        n_filters = inputs.shape[-1] // 2\n",
        "        linear_output = self.activation(inputs[..., :n_filters])\n",
        "        gate = tf.keras.activations.sigmoid(inputs[..., n_filters:])\n",
        "        return self.activation(linear_output) * gate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLO-fC_N9i5g"
      },
      "outputs": [],
      "source": [
        "def wavenet_residual_block(inputs, n_filters, dilation_rate):\n",
        "    z = tf.keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=\"causal\",\n",
        "                            dilation_rate=dilation_rate)(inputs)\n",
        "    z = GatedActivationUnit()(z)\n",
        "    z = tf.keras.layers.Conv1D(n_filters, kernel_size=1)(z)\n",
        "    return tf.keras.layers.Add()([z, inputs]), z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MzwlLu19i5g"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "n_layers_per_block = 3  # 논문에서는 10\n",
        "n_blocks = 1  # 논문에서는 3\n",
        "n_filters = 32  # 논문에서는 128\n",
        "n_outputs = 14  # 논문에서는 256\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=[None, 5])\n",
        "z = tf.keras.layers.Conv1D(n_filters, kernel_size=2, padding=\"causal\")(inputs)\n",
        "skip_to_last = []\n",
        "for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:\n",
        "    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)\n",
        "    skip_to_last.append(skip)\n",
        "\n",
        "z = tf.keras.activations.relu(tf.keras.layers.Add()(skip_to_last))\n",
        "z = tf.keras.layers.Conv1D(n_filters, kernel_size=1, activation=\"relu\")(z)\n",
        "Y_preds = tf.keras.layers.Conv1D(n_outputs, kernel_size=1)(z)\n",
        "\n",
        "full_wavenet_model = tf.keras.Model(inputs=[inputs], outputs=[Y_preds])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJkNRZ_9i5g"
      },
      "source": [
        "5에포크 동안만 훈련하면 효과가 있다는 것을 알 수 있습니다(원하는 경우 더 늘릴 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEYcEAQ39i5g"
      },
      "outputs": [],
      "source": [
        "fit_and_evaluate(full_wavenet_model, longer_train, longer_valid,\n",
        "                 learning_rate=0.1, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNCJjPlg9i5g"
      },
      "source": [
        "이 장에서는 RNN의 기초를 살펴보고 이를 사용하여 시퀀스(즉, 시계열)를 처리하는 방법을 살펴보았습니다. 이 과정에서 CNN을 포함한 시퀀스를 처리하는 다른 방법도 살펴봤습니다. 다음 장에서는 자연어 처리를 위해 RNN을 사용하고, RNN에 대해 자세히 알아볼 것입니다(양방향 RNN, 상태가 있는 RNN과 상태가 없는 RNN, 인코더-디코더, 어텐션 기반 인코더-디코더). 또한 어텐션 전용 아키텍처인 트랜스포머에 대해서도 살펴볼 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhrX9H2X9i5h"
      },
      "source": [
        "# 연습문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrJjUrc9i5h"
      },
      "source": [
        "## 1. to 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcelEXat9i5h"
      },
      "source": [
        "## 9. SketchRNN 데이터셋 다루기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sch1fD4S9i5h"
      },
      "source": [
        "_연습문제: 텐서플로 데이터셋에서 제공하는 SketchRNN 데이터셋으로 분류 모델을 훈련해보세요._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuQeeNbO9i5j"
      },
      "source": [
        "이 데이터셋은 아직 TFDS에서 제공하지 않습니다. 아직 [풀 리퀘스트](https://github.com/tensorflow/datasets/pull/361)가 진행 중입니다. 다행히 이 데이터는 TFRecord로 제공되므로 다운로드해보죠(3,450,000 훈련 스케치와 345,000 테스트 스케치가 포함된 이 데이터셋은 1GB 정도되기 때문에 다운로드 시간이 조금 걸립니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k64P6YUW9i5k"
      },
      "outputs": [],
      "source": [
        "tf_download_root = \"http://download.tensorflow.org/data/\"\n",
        "filename = \"quickdraw_tutorial_dataset_v1.tar.gz\"\n",
        "filepath = tf.keras.utils.get_file(filename,\n",
        "                                   tf_download_root + filename,\n",
        "                                   cache_dir=\".\",\n",
        "                                   extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gPOyTLl9i5k"
      },
      "outputs": [],
      "source": [
        "quickdraw_dir = Path(filepath).parent\n",
        "train_files = sorted(\n",
        "    [str(path) for path in quickdraw_dir.glob(\"training.tfrecord-*\")]\n",
        ")\n",
        "eval_files = sorted(\n",
        "    [str(path) for path in quickdraw_dir.glob(\"eval.tfrecord-*\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe6HDrC59i5k"
      },
      "outputs": [],
      "source": [
        "train_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNJurGkq9i5k"
      },
      "outputs": [],
      "source": [
        "eval_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X45qSSG39i5l"
      },
      "outputs": [],
      "source": [
        "with open(quickdraw_dir / \"eval.tfrecord.classes\") as test_classes_file:\n",
        "    test_classes = test_classes_file.readlines()\n",
        "\n",
        "with open(quickdraw_dir / \"training.tfrecord.classes\") as train_classes_file:\n",
        "    train_classes = train_classes_file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV3hDSEh9i5l"
      },
      "outputs": [],
      "source": [
        "assert train_classes == test_classes\n",
        "class_names = [name.strip().lower() for name in train_classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXI-Ydo99i5l"
      },
      "outputs": [],
      "source": [
        "sorted(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNHGe-PL9i5l"
      },
      "outputs": [],
      "source": [
        "def parse(data_batch):\n",
        "    feature_descriptions = {\n",
        "        \"ink\": tf.io.VarLenFeature(dtype=tf.float32),\n",
        "        \"shape\": tf.io.FixedLenFeature([2], dtype=tf.int64),\n",
        "        \"class_index\": tf.io.FixedLenFeature([1], dtype=tf.int64)\n",
        "    }\n",
        "    examples = tf.io.parse_example(data_batch, feature_descriptions)\n",
        "    flat_sketches = tf.sparse.to_dense(examples[\"ink\"])\n",
        "    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])\n",
        "    lengths = examples[\"shape\"][:, 0]\n",
        "    labels = examples[\"class_index\"][:, 0]\n",
        "    return sketches, lengths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pImOdY959i5l"
      },
      "outputs": [],
      "source": [
        "def quickdraw_dataset(filepaths, batch_size=32, shuffle_buffer_size=None,\n",
        "                      n_parse_threads=5, n_read_threads=5, cache=False):\n",
        "    dataset = tf.data.TFRecordDataset(filepaths,\n",
        "                                      num_parallel_reads=n_read_threads)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)\n",
        "    return dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD9miC7d9i5l"
      },
      "outputs": [],
      "source": [
        "train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)\n",
        "valid_set = quickdraw_dataset(eval_files[:5])\n",
        "test_set = quickdraw_dataset(eval_files[5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8E73Pkc9i5m"
      },
      "outputs": [],
      "source": [
        "for sketches, lengths, labels in train_set.take(1):\n",
        "    print(\"sketches =\", sketches)\n",
        "    print(\"lengths =\", lengths)\n",
        "    print(\"labels =\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LSfQM4v9i5m"
      },
      "outputs": [],
      "source": [
        "def draw_sketch(sketch, label=None):\n",
        "    origin = np.array([[0., 0., 0.]])\n",
        "    sketch = np.r_[origin, sketch]\n",
        "    stroke_end_indices = np.argwhere(sketch[:, -1]==1.)[:, 0]\n",
        "    coordinates = sketch[:, :2].cumsum(axis=0)\n",
        "    strokes = np.split(coordinates, stroke_end_indices + 1)\n",
        "    title = class_names[label.numpy()] if label is not None else \"Try to guess\"\n",
        "    plt.title(title)\n",
        "    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")\n",
        "    for stroke in strokes:\n",
        "        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def draw_sketches(sketches, lengths, labels):\n",
        "    n_sketches = len(sketches)\n",
        "    n_cols = 4\n",
        "    n_rows = (n_sketches - 1) // n_cols + 1\n",
        "    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))\n",
        "    for index, sketch, length, label in zip(range(n_sketches), sketches, lengths, labels):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        draw_sketch(sketch[:length], label)\n",
        "    plt.show()\n",
        "\n",
        "for sketches, lengths, labels in train_set.take(1):\n",
        "    draw_sketches(sketches, lengths, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD29Lqxc9i5m"
      },
      "source": [
        "대부분의 스케치는 100개 포인트 이하로 구성되어 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jraKdgZ59i5w"
      },
      "outputs": [],
      "source": [
        "lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])\n",
        "plt.hist(lengths, bins=150, density=True)\n",
        "plt.axis([0, 200, 0, 0.03])\n",
        "plt.xlabel(\"길이\")\n",
        "plt.ylabel(\"밀도\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noOaYgmW9i5w"
      },
      "outputs": [],
      "source": [
        "def crop_long_sketches(dataset, max_length=100):\n",
        "    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))\n",
        "\n",
        "cropped_train_set = crop_long_sketches(train_set)\n",
        "cropped_valid_set = crop_long_sketches(valid_set)\n",
        "cropped_test_set = crop_long_sketches(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tn7GmcQ9i5x"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dense(len(class_names), activation=\"softmax\")\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\", \"sparse_top_k_categorical_accuracy\"])\n",
        "history = model.fit(cropped_train_set, epochs=2,\n",
        "                    validation_data=cropped_valid_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdqxsYv89i5x"
      },
      "outputs": [],
      "source": [
        "y_test = np.concatenate([labels for _, _, labels in test_set])\n",
        "y_probas = model.predict(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkpmgIzx9i5x"
      },
      "outputs": [],
      "source": [
        "np.mean(tf.keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwUkKkCX9i5x"
      },
      "outputs": [],
      "source": [
        "n_new = 10\n",
        "Y_probas = model.predict(sketches)\n",
        "top_k = tf.nn.top_k(Y_probas, k=5)\n",
        "for index in range(n_new):\n",
        "    plt.figure(figsize=(3, 3.5))\n",
        "    draw_sketch(sketches[index])\n",
        "    plt.show()\n",
        "    print(\"Top-5 predictions:\".format(index + 1))\n",
        "    for k in range(5):\n",
        "        class_name = class_names[top_k.indices[index, k]]\n",
        "        proba = 100 * top_k.values[index, k]\n",
        "        print(\"  {}. {} {:.3f}%\".format(k + 1, class_name, proba))\n",
        "    print(\"Answer: {}\".format(class_names[labels[index].numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuG1-Fe09i5y"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_sketchrnn\", save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6arU0oL9i5y"
      },
      "source": [
        "## 10. 바흐 합창곡\n",
        "\n",
        "_연습문제: [바흐 합창곡](https://homl.info/bach) 데이터셋을 다운로드하여 압축을 풉니다. 이 데이터셋은 요한 제바스티안 바흐가 작곡한 382개의 합창곡으로 구성되어 있습니다. 각 곡은 100에서 640까지 타임 스텝 길이입니다. 각 타임 스텝은 4개의 정수를 담고 있습니다. 각 정수는 피아노 음표의 인덱스에 해당합니다(연주되는 음표가 없다는 것을 의미하는 0은 제외). 코랄의 타임 스텝 시퀀스가 주어지면 다음 타임 스텝(4개의 음표)을 예측할 수 있는 순환 모델, 합성곱 모델 또는 두 가지를 합친 모델을 훈련하세요. 그 다음 이 모델을 사용해 한 번에 하나의 음표씩 바흐와 같은 음악을 생성하세요. 코랄의 시작 부분을 모델에 주입하고 다음 타임 스텝을 예측합니다. 이 타임 스텝을 입력 시퀀스에 추가하여 모델이 다음 음표를 예측하게 만드는 식입니다. 또 바흐를 위한 [구글 두들](https://www.google.com/doodles/celebrating-johann-sebastian-bach)에 사용한 구글의 [Coconet 모델](https://homl.info/coconet)을 확인해보세요._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkor4S2m9i5y"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.get_file(\n",
        "    \"jsb_chorales.tgz\",\n",
        "    \"https://github.com/ageron/data/raw/main/jsb_chorales.tgz\",\n",
        "    cache_dir=\".\",\n",
        "    extract=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_uRoydq9i5y"
      },
      "outputs": [],
      "source": [
        "jsb_chorales_dir = Path(\"datasets/jsb_chorales\")\n",
        "train_files = sorted(jsb_chorales_dir.glob(\"train/chorale_*.csv\"))\n",
        "valid_files = sorted(jsb_chorales_dir.glob(\"valid/chorale_*.csv\"))\n",
        "test_files = sorted(jsb_chorales_dir.glob(\"test/chorale_*.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e3Xjuye9i5y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_chorales(filepaths):\n",
        "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
        "\n",
        "train_chorales = load_chorales(train_files)\n",
        "valid_chorales = load_chorales(valid_files)\n",
        "test_chorales = load_chorales(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFc-vV7C9i5z"
      },
      "outputs": [],
      "source": [
        "train_chorales[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obNXmgJ39i5z"
      },
      "source": [
        "음표의 범위는 36(C1 = 옥타브 1의 C)에서 81(A5 = 옥타브 5의 A)까지이고 무음을 위해 0을 추가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpYPwl-r9i5z"
      },
      "outputs": [],
      "source": [
        "notes = set()\n",
        "for chorales in (train_chorales, valid_chorales, test_chorales):\n",
        "    for chorale in chorales:\n",
        "        for chord in chorale:\n",
        "            notes |= set(chord)\n",
        "\n",
        "n_notes = len(notes)\n",
        "min_note = min(notes - {0})\n",
        "max_note = max(notes)\n",
        "\n",
        "assert min_note == 36\n",
        "assert max_note == 81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL9Pbzff9i5z"
      },
      "source": [
        "이 코랄을 듣기 위한 몇 개의 함수를 만들어 보죠(자세한 내용을 이해할 필요는 없습니다. 사실 MIDI 플레이어처럼 더 간단한 방법이 있지만 그냥 하나의 합성기(synthesizer)를 만들어 보고 싶었습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KURemiW9i5z"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "def notes_to_frequencies(notes):\n",
        "    # 한 옥타브 올라갈 때 주파수는 두배가 됩니다; 옥타브마다 12개의 반음이 있습니다;\n",
        "    # 옥타브 4의 A는 440Hz이고 음표 번호는 69입니다.\n",
        "    return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
        "\n",
        "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
        "    note_duration = 60 / tempo # tempo는 분당 박자 수로 측정합니다\n",
        "    # 매 박자마다 딸깍거리는 소리를 줄이기 위해 주파수를 반올림하여 각 음의 끝에서 샘플을 0에 가깝게 만듭니다.\n",
        "    frequencies = (note_duration * frequencies).round() / note_duration\n",
        "    n_samples = int(note_duration * sample_rate)\n",
        "    time = np.linspace(0, note_duration, n_samples)\n",
        "    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
        "    # (음표 0 = 무음을 포함해) 9Hz 이하인 주파수는 모두 삭제합니다\n",
        "    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
        "    return sine_waves.reshape(-1)\n",
        "\n",
        "def chords_to_samples(chords, tempo, sample_rate):\n",
        "    freqs = notes_to_frequencies(chords)\n",
        "    freqs = np.r_[freqs, freqs[-1:]] # 마지막 음표를 조금 더 길게합니다\n",
        "    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
        "                     for melody in freqs.T], axis=0)\n",
        "    n_fade_out_samples = sample_rate * 60 // tempo # 마지막 음을 희미하게 합니다\n",
        "    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
        "    merged[-n_fade_out_samples:] *= fade_out\n",
        "    return merged\n",
        "\n",
        "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
        "    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
        "    if filepath:\n",
        "        from scipy.io import wavfile\n",
        "        samples = (2**15 * samples).astype(np.int16)\n",
        "        wavfile.write(filepath, sample_rate, samples)\n",
        "        return display(Audio(filepath))\n",
        "    else:\n",
        "        return display(Audio(samples, rate=sample_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH4JWxt69i5z"
      },
      "source": [
        "이제 몇 개의 코랄을 들어 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJGpElrW9i50"
      },
      "outputs": [],
      "source": [
        "for index in range(3):\n",
        "    play_chords(train_chorales[index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXDgTcrS9i50"
      },
      "source": [
        "새로운 코랄을 생성하기 위해서는 이전의 화음이 주어졌을 때 다음 화음을 예측할 수 있는 모델을 훈련해야 합니다. 한 번에 4개의 음표를 예측하는 식으로 다음 화음을 예측한다면 잘 어울리지 않는 음표를 얻게 됩니다(믿으세요. 제가 해 보았습니다). 한 번에 하나의 음표를 예측하는 것이 간단하고 더 낫습니다. 따라서 모든 코랄을 전처리하여 각 화음을 아르페지오로 바꾸어야 합니다(즉, 동시에 연주되는 음표가 아니라 음표의 시퀀스). 그다음 이전의 모든 음표가 주어졌을 때 다음 음표를 예측하는 모델을 훈련할 수 있습니다. 시퀀스-투-시퀀스 방식을 사용하겠습니다. 신경망에 한 윈도를 주입하고 한 타임 스텝 미래로 이동한 윈도를 예측합니다.\n",
        "\n",
        "또한 0에서 46까지 범위를 갖도록 값을 이동시키겠습니다. 여기에서 0은 무음을 나타내고 1에서 46까지는 36(C1)에서 81(A5)까지를 나타냅니다.\n",
        "\n",
        "128 음표(즉, 32개 화음)의 윈도에서 모델을 훈련하겠습니다.\n",
        "\n",
        "이 데이터셋은 메모리에 올라갈 수 있기 때문에 파이썬 코드를 사용해 RAM에서 코랄을 전처리할 수 있지만 여기에서는 tf.data를 사용해 전처리하는 방법을 시연하겠습니다(다음 장에서 tf.data를 사용해 윈도를 만드는 과정을 자세히 설명하겠습니다)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE0RH04-9i50"
      },
      "outputs": [],
      "source": [
        "def create_target(batch):\n",
        "    X = batch[:, :-1]\n",
        "    Y = batch[:, 1:] # 각 스텝에서 아르페지오에 있는 다음 음표를 예측합니다\n",
        "    return X, Y\n",
        "\n",
        "def preprocess(window):\n",
        "    window = tf.where(window == 0, window, window - min_note + 1) # 값 이동\n",
        "    return tf.reshape(window, [-1]) # 아르페지오로 변환\n",
        "\n",
        "def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n",
        "                 window_size=32, window_shift=16, cache=True):\n",
        "    def batch_window(window):\n",
        "        return window.batch(window_size + 1)\n",
        "\n",
        "    def to_windows(chorale):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n",
        "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n",
        "        return dataset.flat_map(batch_window)\n",
        "\n",
        "    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n",
        "    dataset = dataset.flat_map(to_windows).map(preprocess)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(create_target)\n",
        "    return dataset.prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9cjpoUh9i50"
      },
      "source": [
        "훈련 세트, 검증 세트, 테스트 세트를 만듭니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAAvflCd9i52"
      },
      "outputs": [],
      "source": [
        "train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)\n",
        "valid_set = bach_dataset(valid_chorales)\n",
        "test_set = bach_dataset(test_chorales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNRg6SZc9i53"
      },
      "source": [
        "이제 모델을 만듭니다:\n",
        "\n",
        "* 음표를 실수 값으로 모델에 직접 주입할 수 있지만 좋은 결과를 얻지 못할 것입니다. 음표 간의 관계는 단순하지 않습니다. 예를 들어 C3을 C4로 바꾼다면 두 음표 사이에 반음이 12개(즉 한 옥타브) 떨어져 있음에도 멜로디는 여전히 괜찮게 들립니다. 반대로 C3을 C\\#3으로 바꾼다면 바로 다음 음표임에도 화음이 매우 좋지 않습니다. 따라서 `Embedding` 층을 사용해 음표를 작은 벡터 표현으로 바꾸겠습니다(임베딩에 대해서는 16장을 참고하세요). 5-차원 임베딩을 사용하므로 첫 번째 층의 출력은 `[batch_size, window_size, 5]` 크기가 됩니다.\n",
        "* 그 다음 이 데이터를 4개의 `Conv1D` 층을 쌓고 dilation 비율을 두 배씩 늘린 작은 WeveNet 신경망에 주입합니다. 빠른 수렴을 위해 이 층 다음에 `BatchNormalization` 층을 배치합니다.\n",
        "* 그다음 하나의 `LSTM` 층이 장기 패턴을 감지합니다.\n",
        "* 마지막으로 `Dense` 층이 최종 음표 확률을 생성합니다. 타임 스텝과 (무음을 포함해) 가능한 음표 마다 배치에 있는 각 코랄에 대해 하나의 확률을 예측합니다. 따라서 출력 크기는 `[batch_size, window_size, 47]`가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk4GI9rJ9i53"
      },
      "outputs": [],
      "source": [
        "n_embedding_dims = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,\n",
        "                           input_shape=[None]),\n",
        "    tf.keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=4),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_notes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wjHad8l9i53"
      },
      "source": [
        "이제 모델을 컴파일하고 훈련할 준비가 되었습니다!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWM6_7xp9i53"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_set, epochs=20, validation_data=valid_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNU7mPZ9i54"
      },
      "source": [
        "여기서는 하이퍼파라미터 탐색을 많이 수행하지 않았습니다. 자유롭게 이 모델을 사용해 하이퍼파라미터를 탐색하고 최적화해 보세요. 예를 들어 `LSTM` 층을 제거하고 `Conv1D` 층으로 바꿀 수 있습니다. 층의 개수, 학습률, 옵티마이저 등을 실험해 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK8Fux7f9i54"
      },
      "source": [
        "검증 세트에 대한 모델의 성능이 만족스럽다면 모델을 저장하고 테스트 세트에서 마지막으로 평가합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r1qW9yx9i54"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_bach_model\", save_format=\"tf\")\n",
        "model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I10BcUUx9i55"
      },
      "source": [
        "**노트:** 이 예제에서는 테스트 세트가 진짜로 필요하지 않습니다. 모델이 생성한 음악을 듣는 것이 최종 평가가 되기 때문입니다. 따라서 필요하다면 테스트 세트를 훈련 세트에 넣고 모델을 다시 훈련하여 조금 더 나은 모델을 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvRloRch9i57"
      },
      "source": [
        "이제 새로운 코랄을 생성하는 함수를 만들어 보죠. 몇 개의 시드 화음을 주고 이를 (모델이 기대하는 포맷인) 아르페지오로 변환합니다. 그다음 모델을 사용해 다음 음표을 예측합니다. 마지막에 4개씩 음표를 모아서 다시 화음을 만들고 최종 코랄을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnnviWeS9i57"
      },
      "outputs": [],
      "source": [
        "def generate_chorale(model, seed_chords, length):\n",
        "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
        "    arpegio = tf.reshape(arpegio, [1, -1])\n",
        "    for chord in range(length):\n",
        "        for note in range(4):\n",
        "            next_note = model.predict(arpegio, verbose=0).argmax(axis=-1)[:1, -1:]\n",
        "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
        "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
        "    return tf.reshape(arpegio, shape=[-1, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu7-3RjC9i57"
      },
      "source": [
        "이 함수를 테스트하려면 시드 화음이 필요합니다. 테스트 코랄 중 하나에 있는 처음 8개의 화음을 사용해 보죠(실제로 이는 4번 반복되는 2개의 화음입니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK8Ubnk99i58"
      },
      "outputs": [],
      "source": [
        "seed_chords = test_chorales[2][:8]\n",
        "play_chords(seed_chords, amplitude=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy_gsjwA9i58"
      },
      "source": [
        "첫 번째 코랄을 생성할 준비를 마쳤습니다! 56개의 화음을 생성하여 총 64개의 화음, 즉 4 소절(소절마다 4개의 화음인 4/4박으로 가정합니다)을 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGpQLWmI9i58"
      },
      "outputs": [],
      "source": [
        "new_chorale = generate_chorale(model, seed_chords, 56)\n",
        "play_chords(new_chorale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAT5YTAx9i58"
      },
      "source": [
        "이 방식에는 한가지 단점이 있습니다: 너무 보수적인 경우가 많습니다. 실제로 이 모델은 모험을 하지 않아 항상 가장 높은 확률의 음표를 선택합니다. 이전 음표를 반복하면 충분히 듣기 좋고 가장 덜 위험하기 때문에 이 알고리즘은 마지막 음표를 오래 지속시키는 경향이 있습니다. 상당히 지루합니다. 또한 이 모델을 여러 번 실행하면 항상 같은 멜로디를 생성할 것입니다.\n",
        "\n",
        "조금 더 신나게 만들어 보죠! 항상 가장 높은 점수의 음표를 선택하는 대신, 예측된 확률을 기반으로 랜덤하게 다음 음표를 선택하겠습니다. 예를 들어, 모델이 75% 확률로 C3를 예측하고 25% 확률로 G3를 예측했다면 이 확률대로 랜덤하게 두 음표 중 하나를 선택하겠습니다. 또한 `temperature` 매개변수를 추가하여 시스템의 온도(즉 대담성)를 제어하겠습니다. 높은 온도는 예측 확률을 비슷하게 만들어 가능성이 높은 음표의 확률을 줄이고 가능성이 낮은 음표의 확률을 높입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTBYAC-b9i58"
      },
      "outputs": [],
      "source": [
        "def generate_chorale_v2(model, seed_chords, length, temperature=1):\n",
        "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
        "    arpegio = tf.reshape(arpegio, [1, -1])\n",
        "    for chord in range(length):\n",
        "        for note in range(4):\n",
        "            next_note_probas = model.predict(arpegio)[0, -1:]\n",
        "            rescaled_logits = tf.math.log(next_note_probas) / temperature\n",
        "            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
        "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
        "    return tf.reshape(arpegio, shape=[-1, 4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKpx_tU89i58",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)\n",
        "play_chords(new_chorale_v2_cold, filepath=\"bach_cold.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTodHp-q9i59"
      },
      "outputs": [],
      "source": [
        "new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)\n",
        "play_chords(new_chorale_v2_medium, filepath=\"bach_medium.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZX42e1i9i59"
      },
      "outputs": [],
      "source": [
        "new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)\n",
        "play_chords(new_chorale_v2_hot, filepath=\"bach_hot.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqOYgu-69i59"
      },
      "outputs": [],
      "source": [
        "play_chords(test_chorales[2][:64], filepath=\"bach_test_4.wav\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}